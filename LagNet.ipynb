{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c28e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from lagnet import run\n",
    "from utils import construct_dag, seq2dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d85bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[0, 1, 0, 0, 0],\n",
    "                  [0, 0, 1, 0, 0],\n",
    "                  [0, 0, 0, 1, 0],\n",
    "                  [0, 0, 0, 0, 1],\n",
    "                  [0, 0, 0, 0, 0]])\n",
    "\n",
    "X = torch.tensor([[0, 8, 2],\n",
    "                  [0, 1, 8],\n",
    "                  [1, 5, 1],\n",
    "                  [0, 9, 5],\n",
    "                  [2, 2, 9]])\n",
    "\n",
    "L=4\n",
    "K=3\n",
    "d=10\n",
    "target=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb38fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 (0.00 seconds): train loss 46.75\n",
      "Epoch 1 (0.00 seconds): train loss 46.29\n",
      "Epoch 2 (0.00 seconds): train loss 45.84\n",
      "Epoch 3 (0.00 seconds): train loss 45.39\n",
      "Epoch 4 (0.00 seconds): train loss 44.94\n",
      "Epoch 5 (0.00 seconds): train loss 44.47\n",
      "Epoch 6 (0.00 seconds): train loss 44.01\n",
      "Epoch 7 (0.00 seconds): train loss 43.55\n",
      "Epoch 8 (0.00 seconds): train loss 43.10\n",
      "Epoch 9 (0.00 seconds): train loss 42.65\n",
      "Epoch 10 (0.00 seconds): train loss 42.23\n",
      "Epoch 11 (0.00 seconds): train loss 41.81\n",
      "Epoch 12 (0.00 seconds): train loss 41.39\n",
      "Epoch 13 (0.00 seconds): train loss 41.04\n",
      "Epoch 14 (0.00 seconds): train loss 40.69\n",
      "Epoch 15 (0.00 seconds): train loss 40.35\n",
      "Epoch 16 (0.00 seconds): train loss 40.00\n",
      "Epoch 17 (0.00 seconds): train loss 39.65\n",
      "Epoch 18 (0.00 seconds): train loss 39.30\n",
      "Epoch 19 (0.00 seconds): train loss 38.96\n",
      "Epoch 20 (0.00 seconds): train loss 38.61\n",
      "Epoch 21 (0.00 seconds): train loss 38.27\n",
      "Epoch 22 (0.00 seconds): train loss 37.93\n",
      "Epoch 23 (0.00 seconds): train loss 37.59\n",
      "Epoch 24 (0.00 seconds): train loss 37.26\n",
      "Epoch 25 (0.00 seconds): train loss 36.92\n",
      "Epoch 26 (0.00 seconds): train loss 36.59\n",
      "Epoch 27 (0.00 seconds): train loss 36.26\n",
      "Epoch 28 (0.00 seconds): train loss 35.93\n",
      "Epoch 29 (0.00 seconds): train loss 35.60\n",
      "Epoch 30 (0.00 seconds): train loss 35.27\n",
      "Epoch 31 (0.00 seconds): train loss 34.95\n",
      "Epoch 32 (0.00 seconds): train loss 34.62\n",
      "Epoch 33 (0.00 seconds): train loss 34.30\n",
      "Epoch 34 (0.00 seconds): train loss 33.98\n",
      "Epoch 35 (0.00 seconds): train loss 33.66\n",
      "Epoch 36 (0.00 seconds): train loss 33.36\n",
      "Epoch 37 (0.00 seconds): train loss 33.05\n",
      "Epoch 38 (0.00 seconds): train loss 32.75\n",
      "Epoch 39 (0.00 seconds): train loss 32.45\n",
      "Epoch 40 (0.00 seconds): train loss 32.15\n",
      "Epoch 41 (0.00 seconds): train loss 31.85\n",
      "Epoch 42 (0.00 seconds): train loss 31.55\n",
      "Epoch 43 (0.00 seconds): train loss 31.25\n",
      "Epoch 44 (0.00 seconds): train loss 30.95\n",
      "Epoch 45 (0.00 seconds): train loss 30.65\n",
      "Epoch 46 (0.00 seconds): train loss 30.35\n",
      "Epoch 47 (0.00 seconds): train loss 30.05\n",
      "Epoch 48 (0.00 seconds): train loss 29.75\n",
      "Epoch 49 (0.00 seconds): train loss 29.45\n",
      "Epoch 50 (0.00 seconds): train loss 29.15\n",
      "Epoch 51 (0.00 seconds): train loss 28.85\n",
      "Epoch 52 (0.00 seconds): train loss 28.55\n",
      "Epoch 53 (0.00 seconds): train loss 28.25\n",
      "Epoch 54 (0.00 seconds): train loss 27.95\n",
      "Epoch 55 (0.00 seconds): train loss 27.66\n",
      "Epoch 56 (0.00 seconds): train loss 27.36\n",
      "Epoch 57 (0.00 seconds): train loss 27.07\n",
      "Epoch 58 (0.00 seconds): train loss 26.78\n",
      "Epoch 59 (0.00 seconds): train loss 26.49\n",
      "Epoch 60 (0.00 seconds): train loss 26.21\n",
      "Epoch 61 (0.00 seconds): train loss 25.92\n",
      "Epoch 62 (0.00 seconds): train loss 25.64\n",
      "Epoch 63 (0.00 seconds): train loss 25.36\n",
      "Epoch 64 (0.00 seconds): train loss 25.08\n",
      "Epoch 65 (0.00 seconds): train loss 24.80\n",
      "Epoch 66 (0.00 seconds): train loss 24.54\n",
      "Epoch 67 (0.00 seconds): train loss 24.30\n",
      "Epoch 68 (0.00 seconds): train loss 24.05\n",
      "Epoch 69 (0.00 seconds): train loss 23.81\n",
      "Epoch 70 (0.00 seconds): train loss 23.57\n",
      "Epoch 71 (0.00 seconds): train loss 23.33\n",
      "Epoch 72 (0.00 seconds): train loss 23.09\n",
      "Epoch 73 (0.00 seconds): train loss 22.85\n",
      "Epoch 74 (0.00 seconds): train loss 22.62\n",
      "Epoch 75 (0.00 seconds): train loss 22.38\n",
      "Epoch 76 (0.00 seconds): train loss 22.15\n",
      "Epoch 77 (0.00 seconds): train loss 21.92\n",
      "Epoch 78 (0.00 seconds): train loss 21.69\n",
      "Epoch 79 (0.00 seconds): train loss 21.47\n",
      "Epoch 80 (0.00 seconds): train loss 21.24\n",
      "Epoch 81 (0.00 seconds): train loss 21.02\n",
      "Epoch 82 (0.00 seconds): train loss 20.80\n",
      "Epoch 83 (0.00 seconds): train loss 20.58\n",
      "Epoch 84 (0.00 seconds): train loss 20.36\n",
      "Epoch 85 (0.00 seconds): train loss 20.14\n",
      "Epoch 86 (0.00 seconds): train loss 19.93\n",
      "Epoch 87 (0.00 seconds): train loss 19.72\n",
      "Epoch 88 (0.00 seconds): train loss 19.51\n",
      "Epoch 89 (0.00 seconds): train loss 19.30\n",
      "Epoch 90 (0.00 seconds): train loss 19.10\n",
      "Epoch 91 (0.00 seconds): train loss 18.90\n",
      "Epoch 92 (0.00 seconds): train loss 18.69\n",
      "Epoch 93 (0.00 seconds): train loss 18.49\n",
      "Epoch 94 (0.00 seconds): train loss 18.30\n",
      "Epoch 95 (0.00 seconds): train loss 18.10\n",
      "Epoch 96 (0.00 seconds): train loss 17.91\n",
      "Epoch 97 (0.00 seconds): train loss 17.72\n",
      "Epoch 98 (0.00 seconds): train loss 17.54\n",
      "Epoch 99 (0.00 seconds): train loss 17.35\n",
      "Epoch 100 (0.00 seconds): train loss 17.17\n",
      "Epoch 101 (0.00 seconds): train loss 16.99\n",
      "Epoch 102 (0.00 seconds): train loss 16.81\n",
      "Epoch 103 (0.00 seconds): train loss 16.64\n",
      "Epoch 104 (0.00 seconds): train loss 16.46\n",
      "Epoch 105 (0.00 seconds): train loss 16.29\n",
      "Epoch 106 (0.00 seconds): train loss 16.12\n",
      "Epoch 107 (0.00 seconds): train loss 15.95\n",
      "Epoch 108 (0.00 seconds): train loss 15.79\n",
      "Epoch 109 (0.00 seconds): train loss 15.62\n",
      "Epoch 110 (0.00 seconds): train loss 15.46\n",
      "Epoch 111 (0.00 seconds): train loss 15.30\n",
      "Epoch 112 (0.00 seconds): train loss 15.14\n",
      "Epoch 113 (0.00 seconds): train loss 14.98\n",
      "Epoch 114 (0.00 seconds): train loss 14.82\n",
      "Epoch 115 (0.00 seconds): train loss 14.66\n",
      "Epoch 116 (0.00 seconds): train loss 14.50\n",
      "Epoch 117 (0.00 seconds): train loss 14.34\n",
      "Epoch 118 (0.00 seconds): train loss 14.18\n",
      "Epoch 119 (0.00 seconds): train loss 14.03\n",
      "Epoch 120 (0.00 seconds): train loss 13.87\n",
      "Epoch 121 (0.00 seconds): train loss 13.73\n",
      "Epoch 122 (0.00 seconds): train loss 13.58\n",
      "Epoch 123 (0.00 seconds): train loss 13.43\n",
      "Epoch 124 (0.00 seconds): train loss 13.29\n",
      "Epoch 125 (0.00 seconds): train loss 13.15\n",
      "Epoch 126 (0.00 seconds): train loss 13.02\n",
      "Epoch 127 (0.00 seconds): train loss 12.89\n",
      "Epoch 128 (0.00 seconds): train loss 12.76\n",
      "Epoch 129 (0.00 seconds): train loss 12.63\n",
      "Epoch 130 (0.00 seconds): train loss 12.50\n",
      "Epoch 131 (0.00 seconds): train loss 12.38\n",
      "Epoch 132 (0.00 seconds): train loss 12.26\n",
      "Epoch 133 (0.00 seconds): train loss 12.14\n",
      "Epoch 134 (0.00 seconds): train loss 12.02\n",
      "Epoch 135 (0.00 seconds): train loss 11.91\n",
      "Epoch 136 (0.00 seconds): train loss 11.79\n",
      "Epoch 137 (0.00 seconds): train loss 11.68\n",
      "Epoch 138 (0.00 seconds): train loss 11.57\n",
      "Epoch 139 (0.00 seconds): train loss 11.47\n",
      "Epoch 140 (0.00 seconds): train loss 11.36\n",
      "Epoch 141 (0.00 seconds): train loss 11.26\n",
      "Epoch 142 (0.00 seconds): train loss 11.16\n",
      "Epoch 143 (0.00 seconds): train loss 11.06\n",
      "Epoch 144 (0.00 seconds): train loss 10.97\n",
      "Epoch 145 (0.00 seconds): train loss 10.87\n",
      "Epoch 146 (0.00 seconds): train loss 10.78\n",
      "Epoch 147 (0.00 seconds): train loss 10.68\n",
      "Epoch 148 (0.00 seconds): train loss 10.59\n",
      "Epoch 149 (0.00 seconds): train loss 10.50\n",
      "Epoch 150 (0.00 seconds): train loss 10.40\n",
      "Epoch 151 (0.00 seconds): train loss 10.31\n",
      "Epoch 152 (0.00 seconds): train loss 10.22\n",
      "Epoch 153 (0.00 seconds): train loss 10.14\n",
      "Epoch 154 (0.00 seconds): train loss 10.05\n",
      "Epoch 155 (0.00 seconds): train loss 9.96\n",
      "Epoch 156 (0.00 seconds): train loss 9.88\n",
      "Epoch 157 (0.00 seconds): train loss 9.79\n",
      "Epoch 158 (0.00 seconds): train loss 9.71\n",
      "Epoch 159 (0.00 seconds): train loss 9.62\n",
      "Epoch 160 (0.00 seconds): train loss 9.54\n",
      "Epoch 161 (0.00 seconds): train loss 9.46\n",
      "Epoch 162 (0.00 seconds): train loss 9.38\n",
      "Epoch 163 (0.00 seconds): train loss 9.30\n",
      "Epoch 164 (0.00 seconds): train loss 9.22\n",
      "Epoch 165 (0.00 seconds): train loss 9.14\n",
      "Epoch 166 (0.00 seconds): train loss 9.06\n",
      "Epoch 167 (0.00 seconds): train loss 8.98\n",
      "Epoch 168 (0.00 seconds): train loss 8.91\n",
      "Epoch 169 (0.00 seconds): train loss 8.83\n",
      "Epoch 170 (0.00 seconds): train loss 8.75\n",
      "Epoch 171 (0.00 seconds): train loss 8.68\n",
      "Epoch 172 (0.00 seconds): train loss 8.60\n",
      "Epoch 173 (0.00 seconds): train loss 8.53\n",
      "Epoch 174 (0.00 seconds): train loss 8.46\n",
      "Epoch 175 (0.00 seconds): train loss 8.38\n",
      "Epoch 176 (0.00 seconds): train loss 8.31\n",
      "Epoch 177 (0.00 seconds): train loss 8.24\n",
      "Epoch 178 (0.00 seconds): train loss 8.17\n",
      "Epoch 179 (0.00 seconds): train loss 8.10\n",
      "Epoch 180 (0.00 seconds): train loss 8.03\n",
      "Epoch 181 (0.00 seconds): train loss 7.96\n",
      "Epoch 182 (0.00 seconds): train loss 7.89\n",
      "Epoch 183 (0.00 seconds): train loss 7.82\n",
      "Epoch 184 (0.00 seconds): train loss 7.76\n",
      "Epoch 185 (0.00 seconds): train loss 7.69\n",
      "Epoch 186 (0.00 seconds): train loss 7.62\n",
      "Epoch 187 (0.00 seconds): train loss 7.56\n",
      "Epoch 188 (0.00 seconds): train loss 7.49\n",
      "Epoch 189 (0.00 seconds): train loss 7.43\n",
      "Epoch 190 (0.00 seconds): train loss 7.36\n",
      "Epoch 191 (0.00 seconds): train loss 7.30\n",
      "Epoch 192 (0.00 seconds): train loss 7.24\n",
      "Epoch 193 (0.00 seconds): train loss 7.17\n",
      "Epoch 194 (0.00 seconds): train loss 7.11\n",
      "Epoch 195 (0.00 seconds): train loss 7.05\n",
      "Epoch 196 (0.00 seconds): train loss 6.99\n",
      "Epoch 197 (0.00 seconds): train loss 6.93\n",
      "Epoch 198 (0.00 seconds): train loss 6.87\n",
      "Epoch 199 (0.00 seconds): train loss 6.81\n",
      "Epoch 200 (0.00 seconds): train loss 6.75\n",
      "Epoch 201 (0.00 seconds): train loss 6.69\n",
      "Epoch 202 (0.00 seconds): train loss 6.64\n",
      "Epoch 203 (0.00 seconds): train loss 6.58\n",
      "Epoch 204 (0.00 seconds): train loss 6.52\n",
      "Epoch 205 (0.00 seconds): train loss 6.47\n",
      "Epoch 206 (0.00 seconds): train loss 6.41\n",
      "Epoch 207 (0.00 seconds): train loss 6.36\n",
      "Epoch 208 (0.00 seconds): train loss 6.31\n",
      "Epoch 209 (0.00 seconds): train loss 6.25\n",
      "Epoch 210 (0.00 seconds): train loss 6.20\n",
      "Epoch 211 (0.00 seconds): train loss 6.15\n",
      "Epoch 212 (0.00 seconds): train loss 6.09\n",
      "Epoch 213 (0.00 seconds): train loss 6.04\n",
      "Epoch 214 (0.00 seconds): train loss 5.99\n",
      "Epoch 215 (0.00 seconds): train loss 5.94\n",
      "Epoch 216 (0.00 seconds): train loss 5.89\n",
      "Epoch 217 (0.00 seconds): train loss 5.84\n",
      "Epoch 218 (0.00 seconds): train loss 5.80\n",
      "Epoch 219 (0.00 seconds): train loss 5.75\n",
      "Epoch 220 (0.00 seconds): train loss 5.70\n",
      "Epoch 221 (0.00 seconds): train loss 5.66\n",
      "Epoch 222 (0.00 seconds): train loss 5.61\n",
      "Epoch 223 (0.00 seconds): train loss 5.56\n",
      "Epoch 224 (0.00 seconds): train loss 5.52\n",
      "Epoch 225 (0.00 seconds): train loss 5.47\n",
      "Epoch 226 (0.00 seconds): train loss 5.43\n",
      "Epoch 227 (0.00 seconds): train loss 5.39\n",
      "Epoch 228 (0.00 seconds): train loss 5.34\n",
      "Epoch 229 (0.00 seconds): train loss 5.30\n",
      "Epoch 230 (0.00 seconds): train loss 5.26\n",
      "Epoch 231 (0.00 seconds): train loss 5.22\n",
      "Epoch 232 (0.00 seconds): train loss 5.18\n",
      "Epoch 233 (0.00 seconds): train loss 5.14\n",
      "Epoch 234 (0.00 seconds): train loss 5.10\n",
      "Epoch 235 (0.00 seconds): train loss 5.06\n",
      "Epoch 236 (0.00 seconds): train loss 5.02\n",
      "Epoch 237 (0.00 seconds): train loss 4.98\n",
      "Epoch 238 (0.00 seconds): train loss 4.94\n",
      "Epoch 239 (0.00 seconds): train loss 4.90\n",
      "Epoch 240 (0.00 seconds): train loss 4.86\n",
      "Epoch 241 (0.00 seconds): train loss 4.83\n",
      "Epoch 242 (0.00 seconds): train loss 4.79\n",
      "Epoch 243 (0.00 seconds): train loss 4.76\n",
      "Epoch 244 (0.00 seconds): train loss 4.72\n",
      "Epoch 245 (0.00 seconds): train loss 4.69\n",
      "Epoch 246 (0.00 seconds): train loss 4.66\n",
      "Epoch 247 (0.00 seconds): train loss 4.62\n",
      "Epoch 248 (0.00 seconds): train loss 4.59\n",
      "Epoch 249 (0.00 seconds): train loss 4.56\n",
      "Epoch 250 (0.00 seconds): train loss 4.53\n",
      "Epoch 251 (0.00 seconds): train loss 4.50\n",
      "Epoch 252 (0.00 seconds): train loss 4.47\n",
      "Epoch 253 (0.00 seconds): train loss 4.44\n",
      "Epoch 254 (0.00 seconds): train loss 4.41\n",
      "Epoch 255 (0.00 seconds): train loss 4.38\n",
      "Epoch 256 (0.00 seconds): train loss 4.35\n",
      "Epoch 257 (0.00 seconds): train loss 4.33\n",
      "Epoch 258 (0.00 seconds): train loss 4.30\n",
      "Epoch 259 (0.00 seconds): train loss 4.27\n",
      "Epoch 260 (0.00 seconds): train loss 4.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261 (0.00 seconds): train loss 4.22\n",
      "Epoch 262 (0.00 seconds): train loss 4.20\n",
      "Epoch 263 (0.00 seconds): train loss 4.17\n",
      "Epoch 264 (0.00 seconds): train loss 4.15\n",
      "Epoch 265 (0.00 seconds): train loss 4.13\n",
      "Epoch 266 (0.00 seconds): train loss 4.11\n",
      "Epoch 267 (0.00 seconds): train loss 4.08\n",
      "Epoch 268 (0.00 seconds): train loss 4.06\n",
      "Epoch 269 (0.00 seconds): train loss 4.04\n",
      "Epoch 270 (0.00 seconds): train loss 4.02\n",
      "Epoch 271 (0.00 seconds): train loss 4.00\n",
      "Epoch 272 (0.00 seconds): train loss 3.98\n",
      "Epoch 273 (0.00 seconds): train loss 3.96\n",
      "Epoch 274 (0.00 seconds): train loss 3.94\n",
      "Epoch 275 (0.00 seconds): train loss 3.92\n",
      "Epoch 276 (0.00 seconds): train loss 3.91\n",
      "Epoch 277 (0.00 seconds): train loss 3.89\n",
      "Epoch 278 (0.00 seconds): train loss 3.87\n",
      "Epoch 279 (0.00 seconds): train loss 3.85\n",
      "Epoch 280 (0.00 seconds): train loss 3.84\n",
      "Epoch 281 (0.00 seconds): train loss 3.82\n",
      "Epoch 282 (0.00 seconds): train loss 3.81\n",
      "Epoch 283 (0.00 seconds): train loss 3.79\n",
      "Epoch 284 (0.00 seconds): train loss 3.78\n",
      "Epoch 285 (0.00 seconds): train loss 3.76\n",
      "Epoch 286 (0.00 seconds): train loss 3.75\n",
      "Epoch 287 (0.00 seconds): train loss 3.73\n",
      "Epoch 288 (0.00 seconds): train loss 3.72\n",
      "Epoch 289 (0.00 seconds): train loss 3.71\n",
      "Epoch 290 (0.00 seconds): train loss 3.69\n",
      "Epoch 291 (0.00 seconds): train loss 3.68\n",
      "Epoch 292 (0.00 seconds): train loss 3.67\n",
      "Epoch 293 (0.00 seconds): train loss 3.66\n",
      "Epoch 294 (0.00 seconds): train loss 3.64\n",
      "Epoch 295 (0.00 seconds): train loss 3.63\n",
      "Epoch 296 (0.00 seconds): train loss 3.62\n",
      "Epoch 297 (0.00 seconds): train loss 3.61\n",
      "Epoch 298 (0.00 seconds): train loss 3.60\n",
      "Epoch 299 (0.00 seconds): train loss 3.59\n",
      "Total Time: 0.46776413917541504 seconds\n"
     ]
    }
   ],
   "source": [
    "weights = run(A, X, L=L, K=K, d=d, target=target, lam = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aba06f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 2.8085e-02,  2.1938e-02,  1.2761e-02, -5.2004e-03,  4.0459e-03,\n",
       "          -1.8517e-04,  1.8565e-01, -7.3458e-02, -1.0098e-03,  4.7494e-02],\n",
       "         [ 9.4858e-02, -2.3794e-01,  2.1371e-01, -1.2822e-01,  3.6843e-01,\n",
       "           1.7851e-01, -8.2069e-02, -1.5505e-01,  5.1122e-01, -1.0930e-01],\n",
       "         [-9.2518e-02,  2.0562e-01,  8.9490e-10, -1.2029e-01,  3.4133e-02,\n",
       "          -1.8026e-05, -2.2550e-01, -1.4102e-01,  6.8469e-02,  1.2859e-01],\n",
       "         [ 1.5359e-03, -2.7891e-05,  2.8109e-03, -7.2907e-04,  5.3976e-02,\n",
       "          -1.7955e-01,  1.0260e-01,  1.3018e-01, -1.9688e-08,  7.5749e-02]]),\n",
       " tensor([[-0.1370, -0.2830,  0.5740,  0.2581, -0.1198,  0.0909,  0.4940, -0.0097,\n",
       "           0.2150, -0.2648],\n",
       "         [ 0.4919, -0.2833, -0.2218,  0.4073,  0.0161, -0.3318, -0.1295,  0.2751,\n",
       "           0.4554,  0.4677],\n",
       "         [ 0.4975, -0.0948,  0.2334,  0.2828,  0.0957,  0.1917,  0.0338,  0.2017,\n",
       "          -0.2131, -0.0326],\n",
       "         [-0.3269, -0.1416,  0.1048,  0.4706,  0.3468,  0.4878, -0.1057,  0.6076,\n",
       "           0.5026, -0.1120]]),\n",
       " tensor([[-8.6634e-02,  1.1060e-01,  1.5105e-01,  3.9306e-02, -2.9714e-02,\n",
       "          -1.6578e-02,  8.6060e-02, -2.5244e-01,  4.3821e-01,  4.3804e-01],\n",
       "         [ 4.8707e-01, -5.8114e-02,  3.5732e-01, -2.2496e-01, -2.2222e-01,\n",
       "           1.5579e-01, -3.1732e-01,  3.7152e-03, -3.0404e-02,  1.5935e-01],\n",
       "         [ 4.1780e-01,  1.7972e-06, -3.3243e-01, -1.3429e-01,  2.8491e-01,\n",
       "           2.3143e-01, -3.7992e-01, -1.3310e-02, -4.2110e-01,  1.7561e-01],\n",
       "         [ 1.2002e-01, -4.8138e-02, -1.2597e-01, -7.4462e-02, -2.2959e-01,\n",
       "          -1.6155e-02, -5.6710e-02, -2.6456e-01,  4.3522e-01, -1.4026e-01]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cda4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed78ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941c27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03673a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c6de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba174f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78870114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
